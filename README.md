# Esplorazione empirica delle scelte di design per reti convoluzionali con risorse limitate

Negli ultimi anni, il Machine Learning è diventato una tecnologia ampiamente utilizzata in vari settori, come l'automotive per la computer vision e gli assistenti vocali per il riconoscimento del linguaggio naturale. Tuttavia, l'implementazione di modelli di Machine Learning su dispositivi con risorse limitate, come microcontrollori e sensori a bassa potenza, è stata a lungo una sfida tecnologica a causa delle limitazioni di memoria e potenza di calcolo. In risposta a questa sfida, è emersa la tecnologia del Tiny Machine Learning (TinyML), che consente l'elaborazione di dati di sensori su dispositivi embedded a basso consumo energetico senza la necessità di trasferirli a un server remoto, migliorando la latenza e la privacy dei dati.

La classificazione di immagini è una parte fondamentale del Machine Learning, utilizzata in settori come la medicina e l'automazione industriale. Le Convolutional Neural Networks (CNN) sono architetture neurali specificamente progettate per l'elaborazione di immagini, e attraverso il processo di apprendimento supervisionato, riescono a riconoscere e classificare immagini in modo automatico. Tuttavia, i modelli di classificazione di immagini più performanti richiedono notevoli risorse computazionali.

Per affrontare le sfide dell'implementazione di TinyML su dispositivi con risorse limitate, vengono adottate diverse tecniche di ottimizzazione. Queste includono la compressione del modello attraverso il pruning e la quantizzazione, lo scaling delle reti neurali per adattarle alle risorse disponibili, e l'uso della ricerca di architetture neurali ottimali. Queste tecniche consentono di adattare i modelli di TinyML alle diverse piattaforme e limitazioni hardware.

In particolare, lo scaling delle Convolutional Neural Networks è una tecnica chiave per l'implementazione efficiente di TinyML. Questa tecnica permette di regolare la profondità, la larghezza e la risoluzione delle reti neurali per adattarle ai vincoli di memoria e potenza computazionale dei dispositivi. Tuttavia, ottimizzare una rete neurale in base a un determinato budget richiede la risoluzione di un problema di ottimizzazione degli iperparametri di scaling.